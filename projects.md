---
layout: page
title : Projects
permalink: /projects/
---
<div class="manual-post">
  <div class="manual manual-title">
  
<div class="manual-post">
 <p>  <div class="manual-content">
Code available in the github <a href="https://github.com/shehel/">repo</a>
  </div>
</p>
</div>
<br>

<div class="manual-post">
  <div class="manual manual-title">
  <strong>Covid19 Modeling</strong>
  </div>
<img src="covid.png" alt="covid19" title="Covid19 Plot" style="width:480px;height:210px;"/>
<p>  <div class="manual-content">
Modeling Covid19 in Qatar by inferring an exetended SIR model's parameters using MCMC. Also models present and past reproduction rate. Project was <a href="covid19-qatar.herokuapp.com">deployed</a> as a web-app using heroku. 
  </div>
</p>
</div>
<br>

<div class="manual-post">
  <div class="manual manual-title">
  <strong>Propaganda Detection</strong>
  </div>
<img src="propaganda.png" alt="propaganda" title="Propaganda Detection" style="width:480px;height:210px;"/>
<p>  <div class="manual-content">
Word-level propaganda detection using fine-tuned BERT language model. Published in <a href="https://www.aclweb.org/anthology/D19-5011.pdf">NLP4IF 2019</a>. 
  </div>
</p>
</div>
<br>

<div class="manual-post">
  <div class="manual manual-title">
  <strong>Attention Sequence to Sequence</strong>
  </div>
<img src="nito.png" alt="seq2seq" title="Attention - Beam search" style="width:480px;height:210px;"/>
<p>  <div class="manual-content">
Attention model with beam search trained on English phonemes to word dataset. Accuracy of 68%.
  </div>
</p>
</div>
<br>


<div class="manual-post">
  <div class="manual manual-title">
  <strong>Generative Adverserial Networks</strong>
  </div>
<img src="gan.png" alt="GAN" title="GAN trained on MNIST" style="width:100px;height:100px;"/>
<p>  <div class="manual-content">
<a href="https://github.com/shehel/Generative_Models">Collection</a> of GAN and its variants based on Goodfellow's <a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf">work</a> using pyTorch. 
  </div>
</p>
</div>
<br>

<div class="manual-post">
  <div class="manual manual-title">
  <strong>Style Transfer</strong>
  </div>
<img src="style.png" alt="Style Transfer" title="Sampling a horse from the matrix" style="width:288px;height:100px;"/>
<p>  <div class="manual-content">
<a href="https://github.com/shehel/Generative_Models/blob/master/StyleTransfer.ipynb">Recreated</a> Gatys et. al.'s <a href="https://arxiv.org/abs/1508.06576">paper</a> on style transfer using VGG, Keras and Tensorflow. Also <a href="https://github.com/shehel/Generative_Models/blob/master/SuperRes-fastNTransfer.ipynb">implemented</a> the subsequent improved <a href="https://arxiv.org/abs/1603.08155">version</a> using end to end CNNs and 'perceptual loss'.

  </div>
</p>
</div>
<br>


<div class="manual-post">
  <div class="manual manual-title">
  <strong>Machine Learning Algorithms</strong>
  </div>

<p>  <div class="manual-content">
<a href="https://github.com/shehel/ML_algorithms">Algorithms</a> from scratch:
<ul>
  <li>
    Neural Networks
  </li>
  <li>
    Naive Bayes
  </li>
   <li>
    K-means Clustering
  </li>
</ul>
  </div>
</p>
</div>
<br>

<div class="manual-post">
  <div class="manual manual-title">
  <strong>CNN Optimization</strong>
  </div>
<p>  <div class="manual-content">
<a href="https://github.com/shehel/Tasks_Neural-Networks/blob/master/CNN_optimizations.ipynb">Benchmarked</a> on Cifar10 with  techniques including  <a href="https://arxiv.org/abs/1506.01186">cyclical learning rates</a>, <a href="https://arxiv.org/abs/1704.00109">snapshot ensembling</a>, cosine annealing and model architectures.   
  </div>
</p>
</div>
<br>

